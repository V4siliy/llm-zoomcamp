{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# From REST to reasoning: ingest, index, and query with dlt and Cognee\n",
    "\n",
    "- Video: https://www.youtube.com/watch?v=MNt_KK32gys\n",
    "- Homework solution: TBA\n",
    "- [Slides](https://docs.google.com/presentation/d/1oHQilxEVqGGW4S2ctNEE0wHY2LgcjYLaRUziAoinsis/edit?usp=sharing)\n",
    "- [dltHub](https://dlthub.com/)\n",
    "\n",
    "## Basic: What is dlt?\n",
    "- a.k.a data load tool\n",
    "- an open-source Python library that lets you build modern ELT pipelines using just Python code.\n",
    "- It helps you:\n",
    "    - Extract data from APIs, databases, files, or custom sources\n",
    "    - Transform and normalize data\n",
    "    - Load data into destinations like BigQuery, DuckDB, Redshift, etc.\n",
    "    - Manage schemas, state, and incremental loading automatically\n",
    "\n",
    "## Basics: What is Cognee?\n",
    "- [Cognee](https://www.cognee.ai/) is an open-source python library, connects data points and establishes ground truths to improve the accuracy of your AI agents and LLMs.\n",
    "- It lets you:\n",
    "    - Add structured or unstructured data (DataFrames, documents, tables)\n",
    "    - Automatically build a knowledge graph from it\n",
    "    - Ask natural language questions and get grounded, context-rich answers\n",
    "\n",
    "## Basics: What is Kuzu?\n",
    "- [Kuzu](https://kuzudb.com/) is an open-source embedded, scalable, blazing fast graph database.\n",
    "\n",
    "Read more about Cognee and Kuzu here: https://blog.kuzudb.com/post/cognee-kuzu-relational-data-to-knowledge-graph/"
   ],
   "id": "cf43755916a3f957"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-09T18:13:29.445306Z",
     "start_time": "2025-07-09T18:13:23.920357Z"
    }
   },
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import cognee\n",
    "from cognee.shared.logging_utils import get_logger, ERROR\n",
    "from cognee.api.v1.visualize.visualize import visualize_graph\n",
    "from cognee.api.v1.search import SearchType\n",
    "from cognee.modules.engine.models import NodeSet\n",
    "import dlt\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "os.environ[\"GRAPH_DATABASE_PROVIDER\"] = \"kuzu\""
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[2m2025-07-09T18:13:24.251999\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mLogging initialized           \u001B[0m [\u001B[0m\u001B[1m\u001B[34mcognee.shared.logging_utils\u001B[0m]\u001B[0m \u001B[36mcognee_version\u001B[0m=\u001B[35m0.2.0\u001B[0m \u001B[36mos_info\u001B[0m=\u001B[35m'Darwin 24.4.0 (Darwin Kernel Version 24.4.0: Fri Apr 11 18:33:39 PDT 2025; root:xnu-11417.101.15~117/RELEASE_ARM64_T6020)'\u001B[0m \u001B[36mpython_version\u001B[0m=\u001B[35m3.11.12\u001B[0m \u001B[36mstructlog_version\u001B[0m=\u001B[35m25.4.0\u001B[0m\n",
      "\n",
      "\u001B[2m2025-07-09T18:13:24.252564\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mWant to learn more? Visit the Cognee documentation: https://docs.cognee.ai\u001B[0m [\u001B[0m\u001B[1m\u001B[34mcognee.shared.logging_utils\u001B[0m]\u001B[0m\n",
      "\n",
      "\u001B[1mHTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Data we'll be using**\n",
    "\n",
    "In this example, we’ll request data from an API that serves the **NYC taxi dataset**. For these purposes we created an API that can serve the data you are already familiar with.\n",
    "\n",
    "### **API documentation**:\n",
    "- **Data**: Comes in pages of 1,000 records.\n",
    "- **Pagination**: When there’s no more data, the API returns an empty page.\n",
    "- **Details**:\n",
    "  - **Method**: GET\n",
    "  - **URL**: `https://us-central1-dlthub-analytics.cloudfunctions.net/data_engineering_zoomcamp_api`\n",
    "  - **Parameters**:\n",
    "    - `page`: Integer (page number), defaults to 1.\n",
    "\n",
    "Here’s how we design our requester:\n",
    "1. **Request page by page** until we hit an empty page. Since we don’t know how much data is behind the API, we must assume it could be as little as 1,000 records or as much as 10GB.\n",
    "2. **Use a generator** to handle this efficiently and avoid loading all data into memory."
   ],
   "id": "5302ec248b869307"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **We'll be partitioning our data in our own way**\n",
    "\n",
    "1. first_10_days\n",
    "2. second_10_days\n",
    "3. last_10_days\n",
    "\n",
    "We'll be doing this manually for clarity, but dlt also supports partitioning, as you can find [here](https://dlthub.com/docs/plus/ecosystem/iceberg#partitioning)."
   ],
   "id": "3379a89bddf6462b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Step 1: Create DLT resource\n",
    "@dlt.resource(write_disposition=\"replace\", name=\"zoomcamp_data\")\n",
    "def zoomcamp_data():\n",
    "    url = \"https://us-central1-dlthub-analytics.cloudfunctions.net/data_engineering_zoomcamp_api\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df['Trip_Pickup_DateTime'] = pd.to_datetime(df['Trip_Pickup_DateTime'])\n",
    "\n",
    "    # Define buckets\n",
    "    df['tag'] = pd.cut(\n",
    "        df['Trip_Pickup_DateTime'],\n",
    "        bins=[\n",
    "            pd.Timestamp(\"2009-06-01\"),\n",
    "            pd.Timestamp(\"2009-06-10\"),\n",
    "            pd.Timestamp(\"2009-06-20\"),\n",
    "            pd.Timestamp(\"2009-06-30\")\n",
    "        ],\n",
    "        labels=[\"first_10_days\", \"second_10_days\", \"last_10_days\"],\n",
    "        right=False\n",
    "    )\n",
    "\n",
    "    # Drop rows not in the specified range\n",
    "    df = df[df['tag'].notnull()]\n",
    "    yield df\n",
    "\n",
    "\n",
    "# Step 2: Create and run the pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"zoomcamp_pipeline\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"zoomcamp_tagged_data\"\n",
    ")\n",
    "load_info = pipeline.run(zoomcamp_data())"
   ],
   "id": "78fdf6b2793e7eba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T18:13:32.474578Z",
     "start_time": "2025-07-09T18:13:32.426886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = pipeline.dataset().zoomcamp_data.df()\n",
    "\n",
    "dataset[:5]"
   ],
   "id": "fb767ead1f8e07b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     end_lat    end_lon  fare_amt  passenger_count payment_type  start_lat  \\\n",
       "0  40.742963 -73.980072      45.0                1       Credit  40.641525   \n",
       "1  40.740187 -74.005698       6.5                1       Credit  40.722065   \n",
       "2  40.718043 -74.004745      12.5                5       Credit  40.761945   \n",
       "3  40.739637 -73.985233       4.9                1         CASH  40.749802   \n",
       "4  40.730032 -73.852693      25.7                1         CASH  40.776825   \n",
       "\n",
       "   start_lon  tip_amt  tolls_amt  total_amt  trip_distance  \\\n",
       "0 -73.787442      9.0       4.15      58.15          17.52   \n",
       "1 -74.009767      1.0       0.00       8.50           1.56   \n",
       "2 -73.983038      2.0       0.00      15.50           3.37   \n",
       "3 -73.992247      0.0       0.00       5.40           1.11   \n",
       "4 -73.949233      0.0       4.15      29.85          11.09   \n",
       "\n",
       "  trip_dropoff_date_time trip_pickup_date_time  store_and_forward  surcharge  \\\n",
       "0    2009-06-14 23:48:00   2009-06-14 23:23:00                NaN        0.0   \n",
       "1    2009-06-18 17:43:00   2009-06-18 17:35:00                NaN        1.0   \n",
       "2    2009-06-10 18:27:00   2009-06-10 18:08:00                NaN        1.0   \n",
       "3    2009-06-14 23:58:00   2009-06-14 23:54:00                NaN        0.5   \n",
       "4    2009-06-13 13:23:00   2009-06-13 13:01:00                NaN        0.0   \n",
       "\n",
       "  vendor_name             tag  \n",
       "0         VTS  second_10_days  \n",
       "1         VTS  second_10_days  \n",
       "2         VTS  second_10_days  \n",
       "3         VTS  second_10_days  \n",
       "4         VTS  second_10_days  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>fare_amt</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lon</th>\n",
       "      <th>tip_amt</th>\n",
       "      <th>tolls_amt</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_dropoff_date_time</th>\n",
       "      <th>trip_pickup_date_time</th>\n",
       "      <th>store_and_forward</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.742963</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>58.15</td>\n",
       "      <td>17.52</td>\n",
       "      <td>2009-06-14 23:48:00</td>\n",
       "      <td>2009-06-14 23:23:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>second_10_days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.740187</td>\n",
       "      <td>-74.005698</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.722065</td>\n",
       "      <td>-74.009767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2009-06-18 17:43:00</td>\n",
       "      <td>2009-06-18 17:35:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>second_10_days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.718043</td>\n",
       "      <td>-74.004745</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.761945</td>\n",
       "      <td>-73.983038</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.50</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2009-06-10 18:27:00</td>\n",
       "      <td>2009-06-10 18:08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>second_10_days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.739637</td>\n",
       "      <td>-73.985233</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.749802</td>\n",
       "      <td>-73.992247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2009-06-14 23:58:00</td>\n",
       "      <td>2009-06-14 23:54:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VTS</td>\n",
       "      <td>second_10_days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.730032</td>\n",
       "      <td>-73.852693</td>\n",
       "      <td>25.7</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.776825</td>\n",
       "      <td>-73.949233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>29.85</td>\n",
       "      <td>11.09</td>\n",
       "      <td>2009-06-13 13:23:00</td>\n",
       "      <td>2009-06-13 13:01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>second_10_days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T18:13:32.504480Z",
     "start_time": "2025-07-09T18:13:32.500925Z"
    }
   },
   "cell_type": "code",
   "source": "dataset[\"tag\"].value_counts()",
   "id": "ca16ac5e213746b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "first_10_days     481\n",
       "second_10_days    295\n",
       "last_10_days      222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Lets load data into Cognee!**\n",
    "\n",
    "Here, I am using `cognee.add()` and then `cognee.cognify()` directly.\n",
    "\n",
    "If you'd like to learn about how to use relational datasets in cognee, please visit the [docs](https://docs.cognee.ai/tutorials/load-your-relational-database) :)"
   ],
   "id": "f819c9be37373411"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T18:22:15.910974Z",
     "start_time": "2025-07-09T18:22:15.901904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def main():\n",
    "    await cognee.prune.prune_data()\n",
    "    await cognee.prune.prune_system(metadata=True)\n",
    "\n",
    "    # Add the first 10 days\n",
    "    df_set1 = dataset.loc[dataset[\"tag\"] == \"first_10_days\"]\n",
    "    df_set1.drop(columns=[\"tag\"], inplace=True)\n",
    "    df_set1 = df_set1.to_json(orient=\"records\", lines=False)\n",
    "    await cognee.add(df_set1, node_set=[\"first_10_days\"])\n",
    "\n",
    "    # Add the second 10 days\n",
    "    df_set2 = dataset.loc[dataset[\"tag\"] == \"second_10_days\"]\n",
    "    df_set2.drop(columns=[\"tag\"], inplace=True)\n",
    "    df_set2 = df_set2.to_json(orient=\"records\", lines=False)\n",
    "    await cognee.add(df_set2, node_set=[\"second_10_days\"])\n",
    "\n",
    "    # Add the last 10 days\n",
    "    df_set3 = dataset.loc[dataset[\"tag\"] == \"last_10_days\"]\n",
    "    df_set3.drop(columns=[\"tag\"], inplace=True)\n",
    "    df_set3 = df_set3.to_json(orient=\"records\", lines=False)\n",
    "    await cognee.add(df_set3, node_set=[\"last_10_days\"])\n",
    "\n",
    "    await cognee.cognify()\n",
    "\n",
    "    visualization_path = \"/Users/vasiliy/projects/llm-zoomcamp/dlt/content/.artifacts/graph_visualization.html\"\n",
    "    await visualize_graph(visualization_path)"
   ],
   "id": "f7850cb53e4f93d3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "await main()",
   "id": "edcd915d7e1ba605",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Search",
   "id": "1eaafee82868756d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T18:26:37.043877Z",
     "start_time": "2025-07-09T18:26:37.042128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def search_cognee(query, node_set, query_type=SearchType.GRAPH_COMPLETION):\n",
    "    answer = await cognee.search(\n",
    "        query_text=query,\n",
    "        query_type=query_type,\n",
    "        node_type=NodeSet,\n",
    "        node_name=node_set,\n",
    "        top_k=5 # limit search for retrieval\n",
    "    )\n",
    "    return answer"
   ],
   "id": "757f75c68ff13e01",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = await search_cognee(\n",
    "    \"What's in this knowledge graph?\",\n",
    "    node_set=[\"first_10_days\"]\n",
    ")"
   ],
   "id": "bb00dd5431b26cf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T18:27:22.931268Z",
     "start_time": "2025-07-09T18:27:22.928483Z"
    }
   },
   "cell_type": "code",
   "source": "print(results[0])",
   "id": "e7dfe92a336cedcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The knowledge graph contains information about taxi trips including details such as drop-off and pick-up times, fare amounts, payment types, distances, and vendor names for each trip. It includes nodes representing specific trips on June 9, 2009, and their respective connections.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "afb5fddaf5b30c00"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
