{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ResNet-50 for Image Vector Search\n",
    "\n",
    "ResNet-50 is CNN architecture that belongs to the ResNet (Residual Networks) family, a series of models designed to address the challenges associated with training deep neural networks"
   ],
   "id": "6981bf822a9014ba"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-24T19:46:32.230621Z",
     "start_time": "2025-06-24T19:46:32.227511Z"
    }
   },
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "from PIL import Image\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "import torchvision.models as torch_models\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T17:21:33.800943Z",
     "start_time": "2025-06-24T17:21:33.391958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 2048  # ResNet50 feature vector size\n",
    "COLLECTION_NAME = \"resnet-test\"\n",
    "\n",
    "model = torch_models.resnet50(weights=torch_models.ResNet50_Weights.DEFAULT)\n",
    "model.eval()\n",
    "\n",
    "# Remove the final classification layer to get features\n",
    "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])"
   ],
   "id": "aa694f3dd0dd94d0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Qdrant collection with proper configuration",
   "id": "174b6c3aeb318415"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T17:22:34.161310Z",
     "start_time": "2025-06-24T17:22:34.158748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# delete collection\n",
    "# client.delete_collection(collection_name=COLLECTION_NAME)"
   ],
   "id": "d5006e35096c1cad",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T17:22:47.920580Z",
     "start_time": "2025-06-24T17:22:47.777752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "print(f\"‚úÖ Collection '{COLLECTION_NAME}' created successfully\")"
   ],
   "id": "f8dd0a1976abfc69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collection 'resnet-test' created successfully\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T19:34:11.171685Z",
     "start_time": "2025-06-24T19:34:11.166505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),           # ‚úÖ Resize to 256px\n",
    "    transforms.CenterCrop(224),       # ‚úÖ Center crop to 224x224\n",
    "    transforms.ToTensor(),            # ‚úÖ Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),  # ‚úÖ ImageNet normalization\n",
    "])"
   ],
   "id": "8ab306329f5b7d95",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Process image",
   "id": "47db9a679103c939"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T17:43:26.359532Z",
     "start_time": "2025-06-24T17:43:26.306839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_features(image_path):\n",
    "    \"\"\"Extract feature vector from single image\"\"\"\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            features = feature_extractor(input_tensor)\n",
    "            # Flatten to 1D vector\n",
    "            features = features.squeeze().cpu().numpy()\n",
    "\n",
    "        return features.tolist()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "image_path = os.path.join(os.path.abspath(\"\"), \"..\", \"assets/cat.jpg\")\n",
    "vector = extract_features(image_path)\n",
    "\n",
    "\n",
    "len(vector)"
   ],
   "id": "79796fda3774bfb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Process folder\n",
    "\n",
    "Using `pavansanagapati/images-dataset` from kaggle"
   ],
   "id": "36a04fc5dc45d00e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T17:54:05.674387Z",
     "start_time": "2025-06-24T17:54:05.659178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "images_path = os.path.join(os.path.abspath(\"\"), \"..\", \"data\")\n",
    "\n",
    "image_files = []\n",
    "for subdir, _, files in os.walk(images_path):\n",
    "    for file in tqdm(files, desc=\"Loading images\"):\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            image_files.append(os.path.join(subdir, file))\n",
    "\n",
    "print(f\"Found {len(image_files)} images.\")"
   ],
   "id": "422b2e442cd4ff3b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 16844.59it/s]\n",
      "Loading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 202/202 [00:00<00:00, 699050.67it/s]\n",
      "Loading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 202/202 [00:00<00:00, 957343.96it/s]\n",
      "Loading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210/210 [00:00<00:00, 1039910.08it/s]\n",
      "Loading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 202/202 [00:00<00:00, 1167010.20it/s]\n",
      "Loading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 202/202 [00:00<00:00, 1080675.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1018 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Process images in batches",
   "id": "ca6a787820709884"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T17:59:15.081390Z",
     "start_time": "2025-06-24T17:59:15.077480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def upload_batch(points):\n",
    "    \"\"\"Upload batch of points to Qdrant\"\"\"\n",
    "    try:\n",
    "        client.upsert(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            points=points\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error uploading batch: {str(e)}\")"
   ],
   "id": "b94dfba566b89445",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T17:59:54.140340Z",
     "start_time": "2025-06-24T17:59:16.008339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process images in batches\n",
    "batch_size = 32\n",
    "points = []\n",
    "\n",
    "for i, image_path in enumerate(tqdm(image_files, desc=\"Processing images\")):\n",
    "    # Extract features\n",
    "    features = extract_features(image_path)\n",
    "\n",
    "    if features is not None:\n",
    "        # Create point for Qdrant\n",
    "        point = PointStruct(\n",
    "            id=str(uuid.uuid4()),  # Unique ID\n",
    "            vector=features,\n",
    "            payload={\n",
    "                \"filename\": os.path.basename(image_path),\n",
    "                \"full_path\": image_path,\n",
    "                \"file_size\": os.path.getsize(image_path),\n",
    "                \"index\": i\n",
    "            }\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "        # Upload in batches\n",
    "        if len(points) >= batch_size:\n",
    "            upload_batch(points)\n",
    "            points = []\n",
    "\n",
    "print(f\"‚úÖ Successfully processed {len(image_files)} images\")\n",
    "\n",
    "# Show collection info\n",
    "try:\n",
    "    info = client.get_collection(COLLECTION_NAME)\n",
    "    print(f\"\\nüìä Collection '{COLLECTION_NAME}' Info:\")\n",
    "    print(f\"   ‚Ä¢ Vectors: {info.points_count}\")\n",
    "    print(f\"   ‚Ä¢ Vector size: {info.config.params.vectors.size}\")\n",
    "    print(f\"   ‚Ä¢ Distance metric: {info.config.params.vectors.distance}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error getting collection info: {str(e)}\")\n"
   ],
   "id": "d9ca0136adefce87",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1018/1018 [00:38<00:00, 26.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully processed 1018 images\n",
      "\n",
      "üìä Collection 'resnet-test' Info:\n",
      "   ‚Ä¢ Vectors: 992\n",
      "   ‚Ä¢ Vector size: 2048\n",
      "   ‚Ä¢ Distance metric: Cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Search for similar images",
   "id": "9a1385620e51a38c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T19:44:01.767965Z",
     "start_time": "2025-06-24T19:44:01.597172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_image_path = os.path.join(os.path.abspath(\"\"), \"..\", \"assets\", \"magellan.jpg\")\n",
    "query_vector = extract_features(query_image_path)\n",
    "limit = 5\n",
    "\n",
    "if query_vector is None:\n",
    "    print(\"‚ùå Could not process query image\")\n",
    "\n",
    "\n",
    "# Search in Qdrant\n",
    "search_results = client.query_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query=query_vector,\n",
    "    limit=limit\n",
    ")\n",
    "\n",
    "print(f\"üîç Top {limit} similar images to {query_image_path}:\")\n",
    "for i, result in enumerate(search_results.points):\n",
    "    print(f\"   {i+1}. {result.payload['filename']} (similarity: {result.score:.4f})\")\n",
    "\n",
    "print(\"=\" * 7)"
   ],
   "id": "4e3bfcd5950963dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Top 5 similar images to /Users/vasiliy/projects/llm-zoomcamp/02-vector-search/extra/../assets/magellan.jpg:\n",
      "   1. cat.175.jpg (similarity: 0.6932)\n",
      "   2. cat.174.jpg (similarity: 0.6858)\n",
      "   3. cat.160.jpg (similarity: 0.6705)\n",
      "   4. cat.109.jpg (similarity: 0.6544)\n",
      "   5. cat.158.jpg (similarity: 0.6457)\n",
      "=======\n"
     ]
    }
   ],
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
